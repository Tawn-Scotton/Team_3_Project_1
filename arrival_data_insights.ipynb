{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5eb3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a text file for the summary analysis and conclusions\n",
    "file_to_output = os.path.join(\".\", \"Analysis\",\"weather_impact_flight_arrivals_analysis.txt\")\n",
    "\n",
    "# File to Load\n",
    "arr_source_2003_2022 = \"airline_delay_US_2003_to_2022.csv\"\n",
    "airports = \"airports.csv\"\n",
    "states = \"states.csv\"\n",
    "\n",
    "# Read the full arrivals data, airports data and state region data and store into Pandas DataFrames\n",
    "arr_data = pd.read_csv(arr_source_2003_2022)\n",
    "airports = pd.read_csv(airports)\n",
    "states = pd.read_csv(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9e7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'month', 'carrier', 'carrier_name', 'airport', 'airport_name',\n",
       "       'arr_flights', 'arr_del15', 'carrier_ct', 'weather_ct', 'nas_ct',\n",
       "       'security_ct', 'late_aircraft_ct', 'arr_cancelled', 'arr_diverted',\n",
       "       'arr_delay', 'carrier_delay', 'weather_delay', 'nas_delay',\n",
       "       'security_delay', 'late_aircraft_delay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the column names in the arrival flights source csv for reference to wrte them correctly in the rest of the file\n",
    "arr_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825de2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ident', 'type', 'name', 'latitude_deg', 'longitude_deg',\n",
       "       'elevation_ft', 'continent', 'iso_country', 'iso_region',\n",
       "       'municipality', 'scheduled_service', 'gps_code', 'iata_code',\n",
       "       'local_code', 'home_link', 'wikipedia_link', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the column names in the airports source csv for reference to wrte them correctly in the rest of the file\n",
    "airports.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85eed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'State Code', 'Region', 'Division'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the column names in the states source csv for reference to wrte them correctly in the rest of the file\n",
    "states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59aa557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival Flight File Column Data Types\n",
      "year                     int64\n",
      "month                    int64\n",
      "carrier                 object\n",
      "carrier_name            object\n",
      "airport                 object\n",
      "airport_name            object\n",
      "arr_flights            float64\n",
      "arr_del15              float64\n",
      "carrier_ct             float64\n",
      "weather_ct             float64\n",
      "nas_ct                 float64\n",
      "security_ct            float64\n",
      "late_aircraft_ct       float64\n",
      "arr_cancelled          float64\n",
      "arr_diverted           float64\n",
      "arr_delay              float64\n",
      "carrier_delay          float64\n",
      "weather_delay          float64\n",
      "nas_delay              float64\n",
      "security_delay         float64\n",
      "late_aircraft_delay    float64\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "Airport File Column Data Types\n",
      "id                     int64\n",
      "ident                 object\n",
      "type                  object\n",
      "name                  object\n",
      "latitude_deg         float64\n",
      "longitude_deg        float64\n",
      "elevation_ft         float64\n",
      "continent             object\n",
      "iso_country           object\n",
      "iso_region            object\n",
      "municipality          object\n",
      "scheduled_service     object\n",
      "gps_code              object\n",
      "iata_code             object\n",
      "local_code            object\n",
      "home_link             object\n",
      "wikipedia_link        object\n",
      "keywords              object\n",
      "dtype: object\n",
      "---------------------------------------\n",
      "State File Column Data Types\n",
      "State         object\n",
      "State Code    object\n",
      "Region        object\n",
      "Division      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the data type for each column\n",
    "print (\"Arrival Flight File Column Data Types\")\n",
    "print(arr_data.dtypes)\n",
    "print (\"---------------------------------------\")\n",
    "print (\"Airport File Column Data Types\")\n",
    "print(airports.dtypes)\n",
    "print (\"---------------------------------------\")\n",
    "print (\"State File Column Data Types\")\n",
    "print(states.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbe17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data into a single dataset. \n",
    "# Create the dataframe called school_data_complete.  This dataframe has all data from both csv files\n",
    "#Output shows the top 5 rows and last 5 rows of the datas\n",
    "school_data_complete = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "display(school_data_complete.head())\n",
    "display(school_data_complete.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload datasets for airport codes and states.  \n",
    "# From the airports dataset, clean the column called \"indent\"\n",
    "    # check if the first letter of each entry is a K\n",
    "    # if first letter is a K, delete it\n",
    "    # save the dataframe with the column for the shortened text in the indent column\n",
    "    # rename the indent column to be \"AIrport Code\" to match the arr_data dataset\n",
    "    \n",
    "# From the airports dataset, clean the column called iso_region\n",
    "    # check if the first letter of each entry is US-\n",
    "    # if yes, remove the US- at the beginning of the text \n",
    "    # rename the iso_region column to be \"state\" to match the states dataset\n",
    "    \n",
    "# From the state dataset, clean the column called State Code\n",
    "    # rename the State Code column to be \"state\" to match the airports dataset\n",
    "    \n",
    "# Create a smaller dataframe from the airports dataset that only includes the 6 columns: iso_country, indent, iso_region, latitude_deg, longitude_deg, and elevation_ft columns\n",
    "    # iso_country = US\n",
    "    # save dataframe as us_airports\n",
    "    \n",
    "# Combine us_airports and states into 1 dataset merging with column \"state\"\n",
    "    # save the combined dataframe as us_airport_regions\n",
    "    \n",
    "# Combine the us_airport_region dataframe and arr_source_2003_2022.csv\n",
    "    # save as arr_region_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(arr_data.head())\n",
    "#display(arr_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c858a29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'month', 'carrier', 'carrier_name', 'airport', 'airport_name',\n",
       "       'arr_flights', 'arr_del15', 'carrier_ct', 'weather_ct', 'nas_ct',\n",
       "       'security_ct', 'late_aircraft_ct', 'arr_cancelled', 'arr_diverted',\n",
       "       'arr_delay', 'carrier_delay', 'weather_delay', 'nas_delay',\n",
       "       'security_delay', 'late_aircraft_delay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all the column names in the data frame for reference to wrte them correctly in the rest of the file\n",
    "arr_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9482f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                     int64\n",
      "month                    int64\n",
      "carrier                 object\n",
      "carrier_name            object\n",
      "airport                 object\n",
      "airport_name            object\n",
      "arr_flights            float64\n",
      "arr_del15              float64\n",
      "carrier_ct             float64\n",
      "weather_ct             float64\n",
      "nas_ct                 float64\n",
      "security_ct            float64\n",
      "late_aircraft_ct       float64\n",
      "arr_cancelled          float64\n",
      "arr_diverted           float64\n",
      "arr_delay              float64\n",
      "carrier_delay          float64\n",
      "weather_delay          float64\n",
      "nas_delay              float64\n",
      "security_delay         float64\n",
      "late_aircraft_delay    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the data type for each column\n",
    "print(arr_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr_data_full = arr_data.rename(columns={'year': 'Year', \n",
    "                                         'month', 'Month',\n",
    "                                         'carrier', 'DO NOT SHOW',\n",
    "                                         'carrier_name', 'Airline',\n",
    "                                         'airport', 'Airport Code',\n",
    "                                         'airport_name', 'Airport Name',   \n",
    "                                         'arr_flights', 'Number Arriving Flihgts'\n",
    "                                         'arr_del15', \n",
    "                                         'carrier_ct', 'weather_ct', \n",
    "                                         'nas_ct', \n",
    "                                         'security_ct', \n",
    "                                         'late_aircraft_ct', \n",
    "                                         'arr_cancelled', \n",
    "                                         'arr_diverted', \n",
    "                                         'arr_delay', \n",
    "                                         'carrier_delay', \n",
    "                                         'weather_delay', \n",
    "                                         'nas_delay', \n",
    "                                         'security_delay', \n",
    "                                         'late_aircraft_delay'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload datasets for airport codes and states.  \n",
    "# From the airports dataset, clean the column called \"indent\"\n",
    "    # check if the first letter of each entry is a K\n",
    "    # if first letter is a K, delete it\n",
    "    # save the dataframe with the column for the shortened text in the indent column\n",
    "    # rename the indent column to be \"AIrport Code\" to match the arr_data dataset\n",
    "    \n",
    "# From the airports dataset, clean the column called iso_region\n",
    "    # check if the first letter of each entry is US-\n",
    "    # if yes, remove the US- at the beginning of the text \n",
    "    # rename the iso_region column to be \"state\" to match the states dataset\n",
    "    \n",
    "# From the state dataset, clean the column called State Code\n",
    "    # rename the State Code column to be \"state\" to match the airports dataset\n",
    "    \n",
    "# Create a smaller dataframe from the airports dataset that only includes the 6 columns: iso_country, indent, iso_region, latitude_deg, longitude_deg, and elevation_ft columns\n",
    "    # iso_country = US\n",
    "    # save dataframe as us_airports\n",
    "    \n",
    "# Combine us_airports and states into 1 dataset merging with column \"state\"\n",
    "    # save the combined dataframe as us_airport_regions\n",
    "    \n",
    "# Combine the us_airport_region dataframe and arr_source_2003_2022.csv\n",
    "    # save as arr_region_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
